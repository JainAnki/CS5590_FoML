{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4a.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqsoFfEhWs-V"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from csv import reader\n",
        "import random\n",
        "from pandas import DataFrame as df\n",
        "import sklearn.ensemble\n",
        "from sklearn.metrics import accuracy_score\n",
        "from randomforest import RandomForestClassifier\n",
        "import time"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGC_GEFjV-LR",
        "outputId": "4b6d6f55-9945-4dbc-e7bd-c7aa5fec6c5d"
      },
      "source": [
        "# Convert string column to float\n",
        "def str_column_to_float(dataset, column):\n",
        "    for row in dataset:\n",
        "        row[column] = float(row[column].strip())\n",
        "# Convert string column to integer\n",
        "def str_column_to_int(dataset, column):\n",
        "    class_values = [row[column] for row in dataset]\n",
        "    unique = set(class_values)\n",
        "    lookup = dict()\n",
        "    for i, value in enumerate(unique):\n",
        "        lookup[value] = i\n",
        "    for row in dataset:\n",
        "        row[column] = lookup[row[column]]\n",
        "    return lookup\n",
        "\n",
        "with open(\"/content/spam.data.txt\",'r') as f:\n",
        "            plaintext = f.read()\n",
        "plaintext = plaintext.replace(' ',',')    \n",
        "with open(\"spam.data.csv\",'w') as f:\n",
        "    f.write(plaintext)\n",
        "\n",
        "dataset = list()\n",
        "with open(\"spam.data.csv\", 'r') as file:\n",
        "    csv_reader = reader(file)\n",
        "    for row in csv_reader:\n",
        "        if not row:\n",
        "            continue\n",
        "        dataset.append(row)\n",
        "    print (\"Number of records: %d\" % len(dataset))\n",
        "    random.shuffle(dataset)\n",
        "# convert string attributes to integers\n",
        "for i in range(0, len(dataset[0])-1):\n",
        "    str_column_to_float(dataset, i)\n",
        "# convert class column to integers\n",
        "str_column_to_int(dataset, len(dataset[0])-1)\n",
        "df1 = df(dataset)\n",
        "y1 = df1[57]\n",
        "del df1[57]\n",
        "X1  = df1\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1,y1, test_size=0.3, random_state=1234)\n",
        "X_train = X_train1.to_numpy()\n",
        "X_test = X_test1.to_numpy()  \n",
        "y_train = y_train1.to_numpy()\n",
        "y_test = y_test1.to_numpy()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of records: 4601\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xt1xKs7VIFR5",
        "outputId": "f2e31694-c302-49b4-eb89-175120a80ec8"
      },
      "source": [
        "fo = open('Code_output.txt','w')\n",
        "\n",
        "print(\"Number of features used for both kinds of training:\")\n",
        "tic = time.perf_counter()\n",
        "forest = RandomForestClassifier(max_features = 42)\n",
        "forest.fit(X_train, y_train)\n",
        "accuracy = forest.score(X_test, y_test)\n",
        "toc = time.perf_counter()\n",
        "print(\"\\n\")\n",
        "print(\"FINISHED classifying using the code written from scratch. accuracy score : \")\n",
        "print(100*accuracy)\n",
        "\n",
        "time_format = time.strftime(\"Time: %H:%M:%S\", time.gmtime(toc-tic))\n",
        "print(\"Time taken for the output to be evaluated = \", time_format)\n",
        "fo.write ('Code from scratch'+'\\n'+'The accuracy was '+str( 100*accuracy)+ '% on the test data with number of features = 42'+'\\n' + 'Time taken = '+ str(time_format))\n",
        "\n",
        "print('\\n')\n",
        "tic = time.perf_counter()\n",
        "model = sklearn.ensemble.RandomForestClassifier(n_estimators = 50, criterion = 'entropy',max_depth = 25, min_samples_split = 42)\n",
        "model.fit(X_train, y_train)\n",
        "predicted_labels = model.predict(X_test)\n",
        "toc = time.perf_counter()\n",
        "print(\"FINISHED classifying using scikit-learn's builtin library. accuracy score : \")\n",
        "accuracy= accuracy_score(y_test, predicted_labels)\n",
        "print(100*accuracy)\n",
        "\n",
        "print(\"Time taken for the output to be evaluated = \", (toc-tic), \"seconds\")\n",
        "fo.write ('\\n'+'\\n'+'Built-in scikit-learn library'+'\\n'+'The accuracy was '+str( 100*accuracy)+ '% on the test data with number of features = 42' +'\\n' + 'Time taken = '+ str(toc-tic) + ' seconds')\n",
        "\n",
        "fo.close()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of features used for both kinds of training:\n",
            "42\n",
            "\n",
            "\n",
            "FINISHED classifying using the code written from scratch. accuracy score : \n",
            "94.4967414916727\n",
            "Time taken for the output to be evaluated =  Time: 02:51:17\n",
            "\n",
            "\n",
            "FINISHED classifying using scikit-learn's builtin library. accuracy score : \n",
            "93.9174511223751\n",
            "Time taken for the output to be evaluated =  0.34009859599973424 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsOOormwMKIQ"
      },
      "source": [
        "##Inference\n",
        "\n",
        "The **processing** **time** of the **scikit-learn built-in library** is much **reduced** while the **accuracy** of the **code from scratch** is slightly **higher**."
      ]
    }
  ]
}